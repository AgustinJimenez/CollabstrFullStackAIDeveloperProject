# AI Brief Generator - Environment Configuration Example
# Copy this file to .env and configure your settings

# =============================================================================
# AI Provider Configuration
# =============================================================================

# AI provider selection: "ollama" for local development, "openai" for production, "test" for fast testing
AI_PROVIDER=ollama

# OpenAI Configuration (only required when AI_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/api-keys
# AI_PROVIDER_API_KEY=sk-your-openai-api-key-here

# =============================================================================
# Ollama Configuration (for local development)
# =============================================================================

# Ollama server URL (use service name for Docker, localhost for local)
# For Docker development: http://ollama:11434
# For local development: http://localhost:11434
OLLAMA_BASE_URL=http://ollama:11434

# Ollama model to use (must be pulled first)
# Available models: phi4-mini:latest, llama3.2:3b, etc.
OLLAMA_MODEL=phi4-mini:latest

# =============================================================================
# Django Configuration
# =============================================================================

# Django debug mode (True for development, False for production)
DEBUG=True

# Django secret key (generate a new one for production)
# You can generate one at: https://djecrety.ir/
# SECRET_KEY=your-secret-key-here

# Allowed hosts (comma-separated list for production)
# ALLOWED_HOSTS=yourdomain.com,www.yourdomain.com

# =============================================================================
# Database Configuration (Optional)
# =============================================================================

# SQLite is used by default, but you can configure PostgreSQL for production
# DATABASE_URL=postgresql://user:password@localhost:5432/aibrief

# =============================================================================
# Development vs Production Examples
# =============================================================================

# LOCAL DEVELOPMENT WITH OLLAMA:
# AI_PROVIDER=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=phi4-mini:latest
# DEBUG=True

# DOCKER DEVELOPMENT WITH OLLAMA:
# AI_PROVIDER=ollama
# OLLAMA_BASE_URL=http://ollama:11434
# OLLAMA_MODEL=phi4-mini:latest
# DEBUG=True

# FAST TESTING WITH FAKE RESPONSES:
# AI_PROVIDER=test
# DEBUG=True
# (Note: Auto-detected when pytest is running)

# PRODUCTION WITH OPENAI (API key entered via web UI):
# AI_PROVIDER=openai
# DEBUG=False
# ALLOWED_HOSTS=yourdomain.com
# SECRET_KEY=your-production-secret-key
# DATABASE_URL=postgresql://user:password@localhost:5432/aibrief